# Example configuration: Kafka to S3
# 
# Data from different topics will be stored in separate folders:
# s3://my-data-bucket/raw-data/data-topic/date=2024-01-01/hour=12/data_*.parquet
#
source:
  type: kafka
  bootstrap_servers:
    - localhost:9092
  topics:
    - data-topic
  group_id: fs-data-sink-group
  value_format: json  # or arrow_ipc
  batch_size: 1000

sink:
  type: s3
  bucket: my-data-bucket
  prefix: raw-data
  region_name: us-east-1
  compression: snappy  # snappy, gzip, brotli, zstd, none
  partition_by:
    - date
    - hour

telemetry:
  log_level: INFO
  log_format: json  # json or text
  enabled: true
  service_name: fs-data-sink
  otlp_endpoint: http://localhost:4317
  trace_enabled: true
  metrics_enabled: true

pipeline:
  max_batches: null  # null for unlimited
  batch_timeout_seconds: 30
  error_handling: log  # log, raise, or ignore
